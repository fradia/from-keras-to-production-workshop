{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From interactive programming to production ready code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luigi.parameter import IntParameter, Parameter\n",
    "from luigi import LocalTarget, Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.1: Check for existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided Docker Image already contains the dataset. This tasks just checks if everything that is needed is at the right place.\n",
    "\n",
    "*Output*: A folder containing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetExists(Task):\n",
    "    dataset = Parameter(default='../../fruits')\n",
    "    \n",
    "    def output(self):\n",
    "        return LocalTarget(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.2: Create a preprocessing configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration for the deep-learning model is essentially the Keras ImageDataGenerator. For the sake of simplicity we do not parameterize this task. But we can grasp the idea how to do it.\n",
    "\n",
    "*Input*: Nothing required <br>\n",
    "*Output*: A pickled ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "\n",
    "# image processing\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# build your own nets\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configure(Task):\n",
    "    pickle_path = Parameter(default=\"/keras2production/notebooks/2-luigi/exercise-dataset/pickle_files\")\n",
    "    \n",
    "    def output(self):\n",
    "        train_data_gen = ImageDataGenerator(rescale = 1/255)\n",
    "        pickle.dump(train_data_gen, open(self.pickle_path+\"/im_generator.p\", \"wb\" ) )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.3: Run the baseline validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task runs the baseline validation and saves it to a file. The same as before, flexibility can be greatly enhanced by als versioning the baseline validation.\n",
    "\n",
    "*Input*: ExtractDataset, Configure <br>\n",
    "*Output*: A JSON-File containing the baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineValidation(Task):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.4: Train the deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task No.4 trains a Keras model and persists it to the filesystem.\n",
    "\n",
    "*Input*: ExtractDataset, Configure <br>\n",
    "*Output*: A .h5 file representing the model architecture and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_array_gen(im_gen, train_image_files_path, img_width, img_height, batch_size, fruit_list):\n",
    "    return im_gen.flow_from_directory(\n",
    "                train_image_files_path,\n",
    "                target_size = (img_width, img_height),\n",
    "                class_mode = 'categorical',\n",
    "                classes = fruit_list,\n",
    "                color_mode = 'rgb', \n",
    "                batch_size = batch_size,\n",
    "                seed = 42)\n",
    "\n",
    "def create_model(): \n",
    "    model = Sequential()\n",
    "\n",
    "    # first hidden layer\n",
    "    model.add(Conv2D(32, (3, 3), padding = \"same\", input_shape = (img_width, img_height, channels)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # second hidden layer\n",
    "    model.add(Conv2D(16, (3, 3), padding = \"same\"))\n",
    "    model.add(LeakyReLU(alpha = 0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten max filtered output into feature vector \n",
    "    # and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Outputs from dense layer are projected onto output layer\n",
    "    model.add(Dense(output_n))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "class TrainModel(Task):\n",
    "    train_image_files_path = '../../fruits/Training/'\n",
    "    valid_image_files_path = '../../fruits/Test/'\n",
    "    pickle_path = Parameter(default=\"/keras2production/notebooks/2-luigi/exercise-dataset/pickle_files\")\n",
    "    img_width = Parameter(default=20)\n",
    "    img_height = Parameter(default=20)\n",
    "    batch_size = Parameter(default=32)\n",
    "    fruit_list = Parameter(default=[\"Apricot\", \"Avocado\", \"Banana\", \"Clementine\", \"Cocos\", \"Kiwi\", \"Lemon\", \"Limes\", \n",
    "                                    \"Mandarine\", \"Orange\", \"Peach\", \"Pineapple\", \"Plum\", \"Pomegranate\", \"Raspberry\", \"Strawberry\"])\n",
    "    \n",
    "    def requires(self):\n",
    "        yield DatasetExists()\n",
    "        yield Configure()\n",
    "        \n",
    "    def output(self):\n",
    "        return LocalTarget(self.model_path+'/model.h5')\n",
    "    \n",
    "    def run(self):\n",
    "        im_generator = pickle.load(open(self.pickle_path+'/im_generator.p','rb'))\n",
    "        train_image_array_gen = image_array_gen(im_generator, self.train_image_files_path, \n",
    "                                                self.img_width, self.img_height, self.batch_size,self.fruit_list)\n",
    "        valid_image_array_gen = image_array_gen(im_generator, self.valid_image_files_path,\n",
    "                                                self.img_width, self.img_height, self.batch_size,self.fruit_list)\n",
    "        train_samples = train_image_array_gen.n\n",
    "        valid_samples = valid_image_array_gen.n\n",
    "        model = create_model()\n",
    "        model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "              metrics = ['accuracy'])\n",
    "        model.fit_generator(\n",
    "            train_image_array_gen,\n",
    "            steps_per_epoch = int(train_samples / self.batch_size), \n",
    "            epochs = epochs, \n",
    "            validation_data = valid_image_array_gen,\n",
    "            validation_steps = int(valid_samples / self.batch_size),\n",
    "            verbose = 1) \n",
    "        model.save(self.output().path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last task evaluates our model and - if it surpasses the baseline accuracy - saves the evaluation results to the filesystem. Let the task crash if the model does not perform well enough. It's worth an exception!\n",
    "\n",
    "*Input*: ExtractDataset, Configure, TrainModel, BaselineValidation<br>\n",
    "*Output*: A JSON file containing the evaluation results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate(Task):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise Task No.6: Deploy to TensorFlow-Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras model is performing well. Let's deploy it to TensorFlow Serving.\n",
    "\n",
    "It can be loaded with TensorFlow Serving by the following command:\n",
    "tensorflow_model_server --model_name=\"keras_model\" --model_base_path=\"serving/keras_model\"\n",
    "\n",
    "*Input*: TrainModel, Evaluate </br>\n",
    "*Output*: The TensorFlow-Graph and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Export(Task):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
